# 事件管理器设计

## 1. 概念定位

### 1.1 核心抽象

**事件管理器**是流水线编排系统中的**事件记录与查询服务**。

**职责**：
- 记录流水线执行过程中发生的事件
- 提供事件查询能力，支持事件表达式评估
- 管理事件的生命周期

**不负责**：
- ❌ 不是消息队列（不主动推送事件）
- ❌ 不是事件总线（不做事件路由）
- ❌ 不做事件处理（由编排引擎处理）

---

## 2. 事件抽象

### 2.1 事件结构

事件是流水线执行过程中的**状态变化记录**：

```yaml
Event:
  # 事件标识
  id: string                           # 事件唯一 ID
  execution_id: string                 # 所属执行实例
  
  # 事件类型
  type: EventType                      # 事件类型枚举
  
  # 事件源
  source: EventSource
    entity_type: "pipeline" | "node" | "task" | "external"
    entity_id: string                  # pipeline_id, node_id, task_id
  
  # 事件负载
  payload: object                      # 事件携带的数据
  
  # 时间戳
  timestamp: datetime                  # 事件发生时间
```

### 2.2 事件类型

**流水线级别事件**：

| 事件类型 | 事件名称 | 说明 |
|---------|---------|------|
| `pipeline.started` | 流水线启动 | 流水线执行开始 |
| `pipeline.completed` | 流水线完成 | 流水线执行成功完成 |
| `pipeline.failed` | 流水线失败 | 流水线执行失败 |
| `pipeline.cancelled` | 流水线取消 | 流水线执行被取消 |

**节点级别事件**：

| 事件类型 | 事件名称 | 说明 |
|---------|---------|------|
| `{node_id}.started` | 节点启动 | 节点开始执行 |
| `{node_id}.completed` | 节点完成 | 节点执行成功 |
| `{node_id}.failed` | 节点失败 | 节点执行失败 |
| `{node_id}.retrying` | 节点重试 | 节点正在重试 |

**任务级别事件**：

| 事件类型 | 事件名称 | 说明 |
|---------|---------|------|
| `{node_id}.task.started` | 任务启动 | 底层任务开始执行 |
| `{node_id}.task.running` | 任务运行中 | 任务状态更新 |
| `{node_id}.task.completed` | 任务完成 | 底层任务执行完成 |
| `{node_id}.task.failed` | 任务失败 | 底层任务执行失败 |

**外部事件**：

| 事件类型 | 事件名称 | 说明 |
|---------|---------|------|
| `external.{source}.{event}` | 外部系统事件 | 外部系统触发的事件 |

**示例**：
```
event:pipeline.started
event:extract_data.completed
event:transform_data.failed
event:external.data_ready
```

---

## 3. 命名空间隔离

### 3.1 隔离机制

**事件通过 execution_id 隔离**：

```
execution_12345:                        # 执行实例 A
  ├─ event: pipeline.started
  ├─ event: extract_data.completed
  └─ event: transform_data.completed

execution_67890:                        # 执行实例 B（完全独立）
  ├─ event: pipeline.started
  ├─ event: extract_data.completed
  └─ event: transform_data.completed

不同执行实例的事件完全隔离
```

### 3.2 查询作用域

**事件查询始终限定在 execution_id 范围内**：

```
查询接口:
  has_event(execution_id, event_type) → boolean
  get_event(execution_id, event_type) → Event
  query_events(execution_id, filters) → List[Event]

隔离保证:
  - execution_12345 只能查询自己的事件
  - execution_67890 只能查询自己的事件
  - 不存在跨执行实例的事件查询
```

---

## 4. 核心操作

### 4.1 发布事件

**操作**：记录事件到事件存储

```
操作: publish_event(execution_id, event)

输入:
  - execution_id: 执行实例 ID
  - event: 事件对象

处理流程:
  1. 验证 execution_id 有效性
  2. 为事件分配唯一 ID
  3. 记录时间戳
  4. 存储到事件存储
  5. 返回事件 ID

输出:
  - event_id: 事件唯一标识
```

**示例**：

```
编排引擎启动流水线:
  ↓
事件管理器.发布事件(
  execution_id: "exec_12345",
  event: {
    type: "pipeline.started",
    source: { entity_type: "pipeline", entity_id: "etl_pipeline" },
    payload: { version: "1.0.0" },
  }
)
  ↓
事件存储:
  exec_12345/events/evt_001: {
    id: "evt_001",
    execution_id: "exec_12345",
    type: "pipeline.started",
    timestamp: "2025-01-15T10:00:00Z",
    ...
  }
```

### 4.2 检查事件

**操作**：判断事件是否已发生

```
操作: has_event(execution_id, event_type)

输入:
  - execution_id: 执行实例 ID
  - event_type: 事件类型（如 "extract_data.completed"）

处理流程:
  1. 在 execution_id 作用域内查询
  2. 检查是否存在 type == event_type 的事件
  3. 返回布尔值

输出:
  - boolean: true 表示事件已发生，false 表示未发生
```

**示例**：

```
编排引擎评估 startWhen 表达式:
  "event:extract_data.completed"
  ↓
事件管理器.检查事件(
  execution_id: "exec_12345",
  event_type: "extract_data.completed"
)
  ↓
查询结果: true
  ↓
编排引擎: startWhen 条件满足，触发节点执行
```

### 4.3 获取事件

**操作**：获取事件详细信息

```
操作: get_event(execution_id, event_type)

输入:
  - execution_id: 执行实例 ID
  - event_type: 事件类型

处理流程:
  1. 在 execution_id 作用域内查询
  2. 查找 type == event_type 的事件
  3. 返回事件对象（如不存在则返回 null）

输出:
  - Event | null: 事件对象或 null
```

**示例**：

```
编排引擎需要获取事件负载:
  ↓
事件管理器.获取事件(
  execution_id: "exec_12345",
  event_type: "extract_data.completed"
)
  ↓
返回事件对象:
  {
    id: "evt_005",
    execution_id: "exec_12345",
    type: "extract_data.completed",
    timestamp: "2025-01-15T10:05:30Z",
    payload: { row_count: 1000000, duration: 120 }
  }
```

### 4.4 查询事件列表

**操作**：批量查询事件

```
操作: query_events(execution_id, filters)

输入:
  - execution_id: 执行实例 ID
  - filters: 查询过滤条件
    - event_types: 事件类型列表（可选）
    - source: 事件源过滤（可选）
    - time_range: 时间范围（可选）

处理流程:
  1. 在 execution_id 作用域内查询
  2. 应用过滤条件
  3. 返回事件列表（按时间排序）

输出:
  - List[Event]: 事件列表
```

**示例**：

```
查询所有节点完成事件:
  ↓
事件管理器.查询事件(
  execution_id: "exec_12345",
  filters: {
    event_types: ["*.completed"]
  }
)
  ↓
返回:
  [
    { type: "extract_data.completed", timestamp: "..." },
    { type: "transform_data.completed", timestamp: "..." },
    { type: "load_data.completed", timestamp: "..." }
  ]
```

### 4.5 清理事件

**操作**：清理过期事件

```
操作: clear_events(execution_id)

输入:
  - execution_id: 执行实例 ID

处理流程:
  1. 删除 execution_id 作用域内的所有事件
  2. 释放存储空间

使用场景:
  - 流水线执行完成后清理事件
  - 执行实例过期后清理历史事件
```

---

## 5. 与编排引擎的交互

### 5.1 事件发布流程

```
节点执行完成:
  编排引擎 → 任务执行器
    ↓
  任务执行器返回执行结果
    ↓
  编排引擎处理结果:
    - 更新节点状态
    - 写入输出变量到变量池
    ↓
  编排引擎 → 事件管理器.发布事件(
    execution_id,
    event: { type: "node_id.completed" }
  )
    ↓
  事件管理器存储事件
    ↓
  编排引擎继续轮询
```

### 5.2 事件查询流程

```
编排引擎轮询周期:
  ↓
  遍历所有待触发的节点
    ↓
  对于每个节点:
    读取 startWhen 表达式
      ↓
    解析表达式中的事件引用:
      "event:extract_data.completed && event:validate.completed"
      ↓
    查询事件管理器:
      has_event("exec_12345", "extract_data.completed") → true
      has_event("exec_12345", "validate.completed") → true
      ↓
    表达式求值: true && true = true
      ↓
    条件满足 → 触发节点执行
```

### 5.3 时序图

```
编排引擎           任务执行器          事件管理器          变量池

启动流水线
  |
  |---发布事件---->|
  |                | (pipeline.started)
  |                |
  |                |---存储事件--->|
  |                                |
轮询检查节点
  |
  |---查询事件---->|
  |                | has_event("extract_data.completed")?
  |<---返回 false-|
  |
触发节点执行
  |---执行任务---->|
  |                |
  |<---返回结果----|
  |                |
  |---写入变量---->|----------------->|
  |                                    |
  |---发布事件---->|
  |                | (node.completed)
  |                |---存储事件--->|
  |
继续轮询...
```

---

## 6. 存储实现

### 6.1 存储选项

**选项 1：内存存储**（适用于短期执行）

```
结构:
  Map[execution_id, Map[event_type, Event]]

特点:
  - 高性能（纳秒级查询）
  - 易于实现
  - 执行完成后自动清理
  - 不支持跨进程共享
```

**选项 2：Redis 存储**（适用于分布式场景）

```
Key 设计:
  events:{execution_id}:{event_type} → Event JSON

特点:
  - 支持分布式查询
  - 支持 TTL 自动过期
  - 亚毫秒级查询性能
  - 支持多个编排引擎实例
```

**选项 3：数据库存储**（适用于审计追踪）

```
Table: events
  - id: string (PK)
  - execution_id: string (Indexed)
  - event_type: string (Indexed)
  - payload: jsonb
  - timestamp: datetime

特点:
  - 持久化存储
  - 支持复杂查询
  - 支持审计追踪
  - 查询性能较低（毫秒级）
```

### 6.2 推荐方案

**分层存储**：

```
运行时:
  - 使用内存存储（热数据）
  - 事件发生时写入内存

执行完成:
  - 异步写入数据库（冷数据）
  - 用于审计和调试

过期清理:
  - 内存：执行完成后立即清理
  - 数据库：定期清理（如 30 天后）
```

---

## 7. 设计约束

### 7.1 事件不可变

**原则**：事件一旦发布，不可修改或删除

```
发布事件后:
  ✅ 可以查询事件
  ✅ 可以批量清理过期事件
  ❌ 不能修改事件内容
  ❌ 不能删除单个事件
```

**原因**：
- 保证执行过程的可追溯性
- 避免事件状态不一致
- 简化并发控制

### 7.2 事件作用域

**原则**：事件严格限定在 execution_id 范围内

```
✅ 允许:
  - 查询当前执行实例的事件
  - 不同执行实例的事件完全隔离

❌ 禁止:
  - 跨执行实例查询事件
  - 订阅其他执行实例的事件
```

### 7.3 事件轻量化

**原则**：事件存储应保持轻量级

```
建议:
  - payload 不存储大对象
  - 大数据引用存储在变量池
  - 事件 payload < 1KB

示例:
  ❌ 不推荐:
    event.payload.data = [1000000 rows of data]
  
  ✅ 推荐:
    event.payload.data_ref = "s3://bucket/data.parquet"
    变量池.extract_data.output_path = "s3://bucket/data.parquet"
```

---

## 8. 与外部系统的集成

### 8.1 接收外部事件

**场景**：外部系统触发流水线节点

```
外部系统 → API Gateway → 事件管理器

API 请求:
  POST /events
  {
    "execution_id": "exec_12345",
    "event_type": "external.approval.approved",
    "payload": {
      "approver": "alice",
      "decision": "approved"
    }
  }

事件管理器:
  - 验证 execution_id
  - 发布事件
  - 返回确认

编排引擎:
  - 轮询时发现新事件
  - 触发等待该事件的节点
```

**使用场景**：
- 人工审批
- 外部数据就绪通知
- 上游系统完成通知

### 8.2 推送事件到外部系统

**场景**：通知外部系统流水线状态

```
事件管理器 → Event Webhook → 外部系统

配置 Webhook:
  - 订阅特定事件类型
  - 配置回调 URL
  - 配置重试策略

事件发生时:
  1. 事件管理器发布事件
  2. 检查 Webhook 订阅
  3. 异步调用外部 API
  4. 重试失败的调用

示例:
  订阅 "pipeline.completed" 事件
    ↓
  POST https://external-system.com/webhook
  {
    "event_type": "pipeline.completed",
    "execution_id": "exec_12345",
    "timestamp": "..."
  }
```

**使用场景**：
- 通知下游系统
- 触发外部工作流
- 集成监控告警

---

## 9. 设计总结

### 9.1 核心概念

| 概念 | 说明 |
|------|------|
| **事件** | 流水线执行过程中的状态变化记录 |
| **事件管理器** | 事件记录与查询服务 |
| **命名空间隔离** | 通过 execution_id 隔离不同执行实例的事件 |
| **被动查询** | 编排引擎主动查询，不是消息推送 |

### 9.2 关键特性

- **轻量级**：只存储事件记录，不做复杂处理
- **隔离性**：不同执行实例的事件完全隔离
- **不可变**：事件一旦发布不可修改
- **可查询**：支持灵活的事件查询
- **可扩展**：支持外部事件集成

### 9.3 与其他组件的关系

```
编排引擎 (核心)
  ├─ 主动查询事件管理器（判断触发条件）
  ├─ 主动查询变量池（解析输入数据）
  └─ 主动调度任务执行器（执行任务）

事件管理器 (辅助)
  └─ 被动接受查询，提供事件状态

变量池 (辅助)
  └─ 被动接受查询，提供变量值

拉模式架构：编排引擎是主动方，其他组件是被动方
```
