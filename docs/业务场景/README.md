# 训练前数据处理场景汇总

本目录包含 4 个聚焦**训练前数据处理**的真实场景，用于验证数据流引擎的领域模型设计。

---

## 场景概览

| 场景 | 执行模式 | 核心特点 | 验证要点 |
|------|---------|---------|---------|
| [场景1：批量特征工程](./场景1-批量特征工程.md) | **Batch** | 大数据量、并行优化、串行汇聚 | data_ready、并行、同步汇聚 |
| [场景2：增量数据处理](./场景2-增量数据处理.md) | **Scheduled Batch** | 定时调度、时间分区、补跑 | cron、execution_date、catchup |
| [场景3：流式数据清洗](./场景3-流式数据清洗.md) | **Streaming** | 持续运行、窗口聚合、状态管理 | streaming、checkpoint、服务依赖 |
| [场景4：数据标注工作流](./场景4-数据标注工作流.md) | **Batch + 外部事件** | 人在回路、条件路由、多分支汇聚 | external_event、条件执行、可选依赖 |

---

## 按执行模式分类

### Batch（批处理）
**场景 1：批量特征工程**
- 一次性大批量数据处理
- TB 级数据的分布式计算
- 并行优化 + 同步汇聚

### Scheduled Batch（定时批处理）
**场景 2：增量数据处理**
- 定时触发（cron）
- 时间分区数据（execution_date）
- 支持历史补跑（catchup）

### Streaming（流式处理）
**场景 3：流式数据清洗**
- 7x24 持续运行
- 窗口聚合和状态管理
- 秒级延迟

### Batch + 外部事件
**场景 4：数据标注工作流**
- 条件路由
- 外部人工审核等待
- 多分支汇聚

---

## 按数据特征分类

### 大数据量（TB 级）
- **场景 1**：500GB → 200GB 特征数据

### 增量数据（日级）
- **场景 2**：每日 30GB 增量处理

### 流式数据（实时）
- **场景 3**：10000 条/秒持续流

### 小批量数据（万级）
- **场景 4**：10000 条标注任务

---

## 验证的核心设计

### 1. 执行模式（executionMode）

| 模式 | 场景 | 特点 |
|------|------|------|
| **batch** | 场景 1, 4 | 一次性执行，有明确完成状态 |
| **scheduled** | 场景 2 | 定时触发，支持 cron 和 catchup |
| **streaming** | 场景 3 | 持续运行，无完成状态 |

### 2. 依赖等待条件（waitFor）

| 条件 | 场景 | 说明 |
|------|------|------|
| **data_ready** | 场景 1, 2, 4 | 等待数据产出且非空 |
| **completed** | 场景 1, 2, 4 | 等待任务成功完成 |
| **healthy** | 场景 3 | 等待服务可用 |
| **running** | 场景 3 | 等待服务运行中 |
| **external_event** | 场景 4 | 等待外部事件 |

### 3. 高级特性

| 特性 | 场景 | 说明 |
|------|------|------|
| **并行执行** | 场景 1 | 用户特征和物品特征并行 |
| **同步汇聚** | 场景 1 | 特征合并等待两路完成 |
| **条件执行** | 场景 1, 4 | 基于条件决定是否执行 |
| **时间分区** | 场景 2 | execution_date 处理特定日期 |
| **补跑** | 场景 2 | catchup 自动补跑历史 |
| **窗口聚合** | 场景 3 | 5 分钟滚动窗口 |
| **状态管理** | 场景 3 | 去重窗口状态 |
| **Checkpoint** | 场景 3 | 支持故障恢复 |
| **外部等待** | 场景 4 | 等待人工审核（小时级） |
| **多源依赖** | 场景 4 | 合并不同来源数据 |
| **可选依赖** | 场景 4 | 不是所有分支都执行 |

---

## 场景对比

### 场景 1 vs 场景 2：批量 vs 增量

| 维度 | 场景 1（批量特征） | 场景 2（增量处理） |
|------|-------------------|-------------------|
| 触发 | 手动/临时 | **定时（cron）** |
| 数据范围 | 全量（7 天） | **增量（1 天）** |
| 时间概念 | 无 | **execution_date** |
| 数据量 | 500GB | 30GB |
| 频率 | 每周 | **每天** |
| 补跑 | 手动重跑 | **catchup 自动** |

### 场景 2 vs 场景 3：批量 vs 流式

| 维度 | 场景 2（增量批量） | 场景 3（流式清洗） |
|------|-------------------|-------------------|
| 执行模式 | Scheduled Batch | **Streaming** |
| 触发 | 定时（cron） | **消息驱动** |
| 完成状态 | 有 | **无** |
| 延迟 | 小时级 | **秒级** |
| 状态 | 无状态 | **有状态（窗口）** |
| 容错 | 重跑 | **Checkpoint** |

### 场景 1 vs 场景 4：简单依赖 vs 复杂依赖

| 维度 | 场景 1（特征工程） | 场景 4（标注工作流） |
|------|-------------------|---------------------|
| 依赖类型 | 数据就绪、任务完成 | **外部事件、条件** |
| 分支结构 | 并行 → 汇聚 | **条件分流 → 汇聚** |
| 等待时长 | 分钟级 | **小时级** |
| 可选依赖 | 无 | **有** |
| 递归 | 无 | **有（重新标注）** |

---

## 覆盖的数据处理类型

### ETL（Extract, Transform, Load）
- **场景 1**：特征工程（Transform）
- **场景 2**：增量 ETL（全流程）
- **场景 3**：流式 ETL（实时）

### 数据清洗
- **场景 1**：批量清洗和去重
- **场景 2**：增量去重和验证
- **场景 3**：流式清洗和过滤

### 特征工程
- **场景 1**：用户和物品特征生成

### 数据标注
- **场景 4**：自动标注 + 人工审核

---

## 总结

这 4 个场景聚焦**训练前数据处理**，覆盖了：

### 数据处理模式
- ✅ 批量处理（大数据离线计算）
- ✅ 增量处理（定时增量更新）
- ✅ 流式处理（实时数据清洗）
- ✅ 人在回路（标注工作流）

### 核心技术要点
- ✅ 分布式计算（Spark/Flink）
- ✅ 并行优化（独立任务并行）
- ✅ 时间分区（按日期处理）
- ✅ 状态管理（窗口去重）
- ✅ 容错恢复（Checkpoint）
- ✅ 条件路由（动态分流）
- ✅ 外部集成（人工审核）

### 验证的领域模型设计
- ✅ **3 种执行模式**：batch、scheduled、streaming
- ✅ **5 种依赖条件**：data_ready、completed、healthy、running、external_event
- ✅ **10+ 高级特性**：并行、汇聚、条件、窗口、checkpoint、补跑等

通过这些场景，充分验证了数据流引擎在**训练前数据处理**领域的**完整性**和**合理性**。
