# 如何与现有平台集成

## 事件驱动 vs 传统 DAG 依赖

#### 传统 DAG（边）方式的局限性

以 Airflow 为代表的传统调度系统使用显式的边来表达依赖关系：

```python
# Airflow 示例
task_a >> task_b  # task_b 依赖 task_a
task_a >> [task_c, task_d]  # 并行分支
```

**核心问题**：

- **静态拓扑**：依赖关系在定义时固化，无法动态调整
- **完成驱动**：只能表达"A完成后执行B"，无法表达其他状态依赖
- **无环约束**：DAG 不支持循环逻辑（流处理的停止-重启场景）
- **有限控制流**：条件分支、动态汇聚需要引入特殊控制节点

---

### 事件驱动容易表达，DAG 难以实现的依赖场景

#### 1. 动态条件分支 ⭐⭐⭐⭐⭐

**需求**：根据数据质量分数决定是"直接入库"还是"人工审批"

**DAG 方式**：

```python
# ❌ 需要 BranchOperator 这种伪节点
def quality_gate(**context):
    score = context['ti'].xcom_pull(task_ids='quality_check')
    return 'high_quality_path' if score > 0.9 else 'manual_review_path'

branching = BranchPythonOperator(
    task_id='quality_gate',
    python_callable=quality_gate
)
quality_check >> branching >> [high_quality, manual_review]
```

**问题**：

- 引入额外的控制节点
- 分支逻辑藏在 Python 代码里，不是声明式
- 难以在配置文件中表达

**事件驱动**：

```yaml
# ✅ 声明式条件订阅，无需控制节点
nodes:
  - id: quality_check
    startWhen: "event:load_data.completed"

  # 高质量路径
  - id: direct_ingest
    startWhen: "event:quality_check.completed && {{ quality_check.score > 0.9 }}"

  # 低质量路径
  - id: manual_review
    startWhen: "event:quality_check.completed && {{ quality_check.score <= 0.9 }}"
```

---

#### 2. OR 汇聚（任一完成即触发）⭐⭐⭐⭐⭐

**需求**：多个数据源并行处理，只要任意一个完成就继续执行

**DAG 方式**：

```python
# ❌ 内置 trigger_rule 有限
source_a = SparkOperator(task_id='source_a')
source_b = SparkOperator(task_id='source_b')
source_c = SparkOperator(task_id='source_c')

merge = SparkOperator(
    task_id='merge',
    trigger_rule='one_success'  # 只支持 all_success, one_success, none_failed 等
)
[source_a, source_b, source_c] >> merge
```

**问题**：

- 无法表达"至少 2 个成功"等复杂逻辑
- 无法根据数据质量动态选择

**事件驱动**：

```yaml
# ✅ 灵活的布尔表达式
nodes:
  - id: source_a
    startWhen: "event:pipeline.started"
  - id: source_b
    startWhen: "event:pipeline.started"
  - id: source_c
    startWhen: "event:pipeline.started"

  # OR 汇聚：任意一个完成
  - id: merge
    startWhen: "event:source_a.completed || event:source_b.completed || event:source_c.completed"

  # 至少 2 个成功
  - id: quality_merge
    startWhen: |
      (event:source_a.completed && event:source_b.completed) ||
      (event:source_a.completed && event:source_c.completed) ||
      (event:source_b.completed && event:source_c.completed)
```

---

#### 3. 循环依赖（停止-重启）⭐⭐⭐⭐⭐

**需求**：流处理任务根据配置变更动态停止并重启

**DAG 方式**：

```text
❌ DAG 是"有向无环图"，本质上不支持循环！
streaming_task → stop → restart → streaming_task (循环依赖)
```

**事件驱动**：

```yaml
# ✅ 通过事件自然表达循环
nodes:
  - id: streaming_task
    startWhen: "event:pipeline.started"
    stopWhen: "event:config_updated || event:resource_maintenance"
    restartWhen: "event:streaming_task.stopped && {{ config_ready }}"
```

**执行流程**：

```text
启动 → 运行中 → 配置更新 → 停止 → 发布 stopped 事件 → 重启 → 运行中（循环）
```

---

#### 4. 超时与回退（竞态条件）⭐⭐⭐⭐

**需求**：人工审批等待 24 小时，超时则自动降级

**DAG 方式**：

```python
# ❌ 需要 Sensor 轮询，且难以协调竞态
approval = ApprovalTask()
timeout_sensor = TimeSensor(timeout=86400)

# 问题：如何表达"优先等待审批，超时则执行降级"？
# 两个分支如何互斥？
```

**事件驱动**：

```yaml
# ✅ 任务自动发布超时事件
nodes:
  - id: manual_approval
    startWhen: "event:quality_check.completed"
    timeout: 24h  # 任务定义中声明超时

  # 审批通过路径
  - id: approved_ingest
    startWhen: "event:manual_approval.approved"

  # 审批超时或拒绝路径
  - id: timeout_fallback
    startWhen: "event:manual_approval.timeout || event:manual_approval.rejected"
```

---

#### 5. 外部事件触发 ⭐⭐⭐⭐

**需求**：根据外部系统事件触发执行（Kafka 消息、Webhook）

**DAG 方式**：

```python
# ❌ 需要 Sensor 轮询，效率低下
data_sensor = S3KeySensor(
    bucket_key='data/{{ ds }}/*.parquet',
    poke_interval=60  # 每分钟轮询一次！
)
process = SparkOperator(task_id='process')
data_sensor >> process
```

**事件驱动**：

```yaml
# ✅ 订阅外部事件（通过平台 API 发布）
nodes:
  - id: process
    startWhen: "event:data_source.data_available && {{ record_count > 1000 }}"
```

外部系统通过 REST API 发布事件：

```bash
POST /api/v1/executions/{executionId}/events
{
  "eventType": "data_source.data_available",
  "payload": {"record_count": 50000}
}
```

---

#### 6. 跨 Pipeline 依赖 ⭐⭐⭐⭐

**需求**：Pipeline A 完成后自动触发 Pipeline B

**DAG 方式**：

```python
# ❌ 需要特殊 Operator
trigger_b = TriggerDagRunOperator(
    task_id='trigger_pipeline_b',
    trigger_dag_id='pipeline_b'
)
```

**问题**：

- 依赖关系不清晰（藏在 Operator 配置里）
- 无法订阅特定节点事件
- 状态传递受限（XCom 大小限制）

**事件驱动**：

```yaml
# Pipeline B 订阅 Pipeline A 的完成事件
pipelineId: pipeline_b
nodes:
  - id: consume_a_result
    startWhen: "event:pipeline_a.completed && {{ pipeline_a.status == 'success' }}"
    inputBindings:
      data: "{{ pipeline_a.output_path }}"
```

甚至可以订阅 Pipeline A 内部节点：

```yaml
startWhen: "event:pipeline_a.quality_check.completed && {{ quality_score < 0.8 }}"
```

---

#### 7. 条件重试（基于失败原因）⭐⭐⭐

**需求**：网络错误重试，数据错误不重试

**DAG 方式**：

```python
# ❌ 固定重试策略，无法区分失败类型
task = SparkOperator(
    retries=3,
    retry_delay=timedelta(minutes=5)
)
```

**事件驱动**：

```yaml
# ✅ 条件重试
nodes:
  - id: process
    startWhen: "event:load.completed"
    retryWhen: |
      event:process.failed &&
      {{ error_type in ['NetworkError', 'TimeoutError'] }} &&
      {{ retry_count < 3 }}

  # 数据错误走人工修复
  - id: manual_fix
    startWhen: |
      event:process.failed &&
      {{ error_type == 'DataValidationError' }}
```

---

#### 8. 状态依赖（等待某个状态）⭐⭐⭐⭐

**需求**：等待流任务"健康运行"，而非等待完成

**DAG 方式**：

```text
❌ DAG 只能表达"完成后执行"，无法表达"运行中且健康时执行"
```

**事件驱动**：

```yaml
# ✅ 订阅健康状态
nodes:
  - id: streaming_producer
    startWhen: "event:pipeline.started"

  - id: streaming_consumer
    # 不等 producer 完成，而是等它健康运行
    startWhen: "event:streaming_producer.started && {{ streaming_producer.health == 'healthy' }}"
```

---

### 对比总结表

| 依赖场景               | DAG 表达能力 | 事件驱动表达能力 | 关键差异                            |
| ---------------------- | ------------ | ---------------- | ----------------------------------- |
| **简单顺序依赖** | ⭐⭐⭐⭐⭐   | ⭐⭐⭐⭐⭐       | 两者都方便                          |
| **并行分支**     | ⭐⭐⭐⭐⭐   | ⭐⭐⭐⭐⭐       | 两者都方便                          |
| **动态条件分支** | ⭐⭐         | ⭐⭐⭐⭐⭐       | 事件驱动声明式，DAG 需控制节点      |
| **OR 汇聚**      | ⭐⭐         | ⭐⭐⭐⭐⭐       | DAG 规则有限，事件驱动任意表达式    |
| **循环依赖**     | ❌           | ⭐⭐⭐⭐⭐       | DAG 无法表达，事件驱动自然支持      |
| **超时回退**     | ⭐           | ⭐⭐⭐⭐⭐       | DAG 需轮询，事件驱动事件机制        |
| **外部事件**     | ⭐           | ⭐⭐⭐⭐⭐       | DAG 需轮询 Sensor，事件驱动实时响应 |
| **跨 Pipeline**  | ⭐⭐         | ⭐⭐⭐⭐⭐       | DAG 需特殊 Operator，事件驱动松耦合 |
| **条件重试**     | ⭐           | ⭐⭐⭐⭐⭐       | DAG 固定策略，事件驱动细粒度控制    |
| **状态依赖**     | ❌           | ⭐⭐⭐⭐⭐       | DAG 只能等完成，事件驱动可等状态    |

---

### 核心洞察

**DAG 的本质限制**：

1. **静态拓扑**：依赖关系在定义时固化
2. **完成驱动**：只能表达"A 完成后执行 B"
3. **无环约束**：不支持循环逻辑
4. **有限控制流**：分支/汇聚需要特殊节点

**事件驱动的优势**：

1. **动态订阅**：运行时根据条件决定是否触发
2. **状态驱动**：可以订阅任意状态变化（started、healthy、timeout 等）
3. **循环自然**：通过事件自然表达停止-重启
4. **声明式控制流**：条件分支通过表达式声明，无需控制节点

**关键差异**：

> **DAG 适合确定性的依赖关系**（A 一定要等 B 完成）
> **事件驱动适合条件性的依赖关系**（A 在满足条件 X 时等待事件 E）

---

## 推荐策略

### 简单场景：使用 DAG 方式

如果 Pipeline 满足以下特征，传统 DAG 方式足够：

- 纯粹的顺序依赖（A → B → C）
- 简单的并行分支（无条件）
- 批处理任务，无流处理
- 无外部事件触发
- 无跨 Pipeline 依赖

**优势**：概念简单、易于理解、性能高效

---

### 复杂场景：使用事件驱动

如果 Pipeline 包含以下任一特征，建议使用事件驱动：

- ✅ 复杂条件分支（根据数据质量、业务规则）
- ✅ 动态汇聚（OR、至少 N 个）
- ✅ 流处理任务（停止/重启）
- ✅ 人工审批或长时间等待
- ✅ 外部事件触发（Kafka、Webhook、定时）
- ✅ 跨 Pipeline 协作
- ✅ 条件重试或降级

**优势**：灵活性高、可扩展性强、支持复杂编排

---

### 混合模式

在同一个平台内，可以支持两种模式：

```yaml
# 简单 Pipeline：DAG 方式
pipelineDefinition:
  dependencies:
    - [extract, transform]
    - [transform, load]

# 复杂 Pipeline：事件驱动
pipelineDefinition:
  nodes:
    - id: extract
      startWhen: "event:pipeline.started"
    - id: transform
      startWhen: "event:extract.completed && {{ extract.row_count > 0 }}"
```

**实现**：

- DAG 方式在底层转换为事件订阅（`startWhen: "event:upstream.completed"`）
- 用户可以根据场景选择更合适的表达方式

---

## 参考资料

- [ADR-001: 事件驱动执行模型](./ADRs/001-event-driven-execution.md)
- [场景 5 执行时序图](../需求分析/场景5执行时序图.md)
- [事件总线技术选型](./事件总线技术选型.md)
