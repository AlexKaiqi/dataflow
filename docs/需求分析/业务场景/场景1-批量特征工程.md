# 场景 1：批量特征工程

## 场景概述

**业务需求**：每周基于历史数据生成训练特征

**执行模式**：纯 Batch（一次性批处理）

**数据规模**：500GB → 200GB

**执行时长**：约 5 小时

**核心特点**：大数据量、复杂计算、串行依赖、数据就绪检查

---

## 数据流程图

```text
历史日志提取（500GB）
  ↓
数据清洗和过滤（450GB）
  ↓
┌───────────────────┴───────────────────┐
│                                       │
用户行为特征工程（50GB）    物品特征工程（20GB）
│                                       │
└───────────────────┬───────────────────┘
  ↓
特征合并和验证（200GB）
  ↓
数据质量报告
```

---

## 详细步骤

### 1. 历史日志提取

**输入**：数据仓库中过去 7 天的用户行为日志

**处理**：
- 按时间范围过滤
- 去除测试用户数据
- 数据采样（如果数据量过大）

**输出**：原始日志（Parquet 格式）

**数据量**：约 500GB

**执行时间**：30 分钟

### 2. 数据清洗和过滤

**输入**：原始行为日志

**处理**：
- 去除重复记录
- 过滤异常数据（缺失字段、异常值）
- 标准化字段格式
- 数据去重

**输出**：清洗后的日志

**数据量**：约 450GB

**执行时间**：45 分钟

### 3. 用户行为特征工程

**输入**：清洗后的行为日志

**处理**：
- 用户点击序列构建
- 用户活跃度统计（7天内点击次数、浏览时长）
- 用户兴趣标签聚合
- 时间特征提取（活跃时段、星期分布）

**输出**：用户特征表

**数据量**：约 50GB（1000 万用户）

**执行时间**：1.5 小时

### 4. 物品特征工程

**输入**：清洗后的行为日志 + 商品基础信息

**处理**：
- 商品点击率/转化率统计
- 商品类目/标签编码
- 商品协同过滤特征
- 商品文本特征（标题/描述）向量化

**输出**：物品特征表

**数据量**：约 20GB（100 万商品）

**执行时间**：1 小时

**说明**：与步骤 3 并行执行

### 5. 特征合并和验证

**输入**：用户特征表 + 物品特征表 + 行为日志

**处理**：
- 生成训练样本（用户-物品对）
- 正负样本采样（1:4 比例）
- 特征拼接和对齐
- 数据分区（训练集/验证集/测试集 = 8:1:1）
- 特征统计验证（缺失率、分布检查）

**输出**：训练数据集（Parquet 格式）

**数据量**：约 200GB（5 亿样本）

**执行时间**：1.5 小时

### 6. 数据质量报告

**输入**：最终训练数据集

**处理**：
- 样本量统计
- 特征覆盖率检查
- 正负样本比例验证
- 生成数据质量报告

**输出**：质量报告（JSON）

**执行时间**：10 分钟

---

## 特点分析

### ✅ 验证的设计要点

1. **数据就绪检查**：等待上游数据产出且验证数据非空
2. **并行执行**：用户特征和物品特征可并行计算
3. **同步汇聚**：特征合并需等待两路特征都完成
4. **条件执行**：数据质量不达标时阻止下游
5. **大数据处理**：TB 级数据的分布式计算

### 核心依赖关系

| 步骤 | 依赖类型 | 等待条件 | 说明 |
|------|---------|---------|------|
| 数据清洗 | **data_ready** | 日志提取完成且非空 | 验证数据量 > 0 |
| 用户特征 | **data_ready** | 清洗数据完成 | 串行依赖 |
| 物品特征 | **data_ready** | 清洗数据完成 | 与用户特征并行 |
| 特征合并 | **completed** | 用户+物品特征都完成 | 同步汇聚 |
| 质量报告 | **data_ready** | 合并数据完成且验证通过 | 数据量和质量检查 |

---

## Pipeline 定义

```yaml
pipeline:
  name: "batch_feature_engineering"
  description: "批量特征工程流水线"

  inputVariables:
    - name: "start_date"
      type: "string"
      description: "数据起始日期"
    - name: "end_date"
      type: "string"
      description: "数据结束日期"

  nodes:
    # 步骤 1：数据提取
    - alias: "log_extraction"
      type: "task"
      executionMode: "batch"
      trigger: "cron:@manual"  # 手动触发
      taskRef:
        namespace: "com.company.feature"
        name: "hive_extractor"
        version: "1.0.0"
      inputs:
        table: "user_behavior_logs"
        start_date: "{{pipe.start_date}}"
        end_date: "{{pipe.end_date}}"
        output_format: "parquet"
      executionPolicy:
        timeout: 1800
        resourceId: "spark_cluster_large"

    # 步骤 2：数据清洗
    - alias: "data_cleaning"
      type: "task"
      executionMode: "batch"
      trigger: "event:log_extraction.succeeded"
      failWhen: "log_extraction.output.row_count == 0"
      taskRef:
        namespace: "com.company.feature"
        name: "data_cleaner"
        version: "1.0.0"
      inputs:
        input_path: "{{log_extraction.output_path}}"
      executionPolicy:
        timeout: 2700

    # 步骤 3：用户特征工程（并行）
    - alias: "user_features"
      type: "task"
      executionMode: "batch"
      trigger: "event:data_cleaning.succeeded"
      taskRef:
        namespace: "com.company.feature"
        name: "user_feature_generator"
        version: "2.0.0"
      inputs:
        cleaned_data: "{{data_cleaning.output_path}}"
      executionPolicy:
        timeout: 5400

    # 步骤 4：物品特征工程（并行）
    - alias: "item_features"
      type: "task"
      executionMode: "batch"
      trigger: "event:data_cleaning.succeeded"
      taskRef:
        namespace: "com.company.feature"
        name: "item_feature_generator"
        version: "2.0.0"
      inputs:
        cleaned_data: "{{data_cleaning.output_path}}"
        item_meta: "s3://data/item_metadata.parquet"
      executionPolicy:
        timeout: 3600

    # 步骤 5：特征合并
    - alias: "feature_merge"
      type: "task"
      executionMode: "batch"
      trigger: "event:user_features.succeeded && event:item_features.succeeded"
      failWhen: "user_features.output.row_count == 0 || item_features.output.row_count == 0"
      alertWhen: "feature_merge.output.sample_count < 100000000"
      taskRef:
        namespace: "com.company.feature"
        name: "feature_merger"
        version: "1.0.0"
      inputs:
        user_features: "{{user_features.output_path}}"
        item_features: "{{item_features.output_path}}"
        behavior_logs: "{{data_cleaning.output_path}}"
        negative_sampling_ratio: 4
        split_ratio: "8:1:1"
      alertConfig:
        channel: "slack"
        severity: "warning"
        message: "样本量低于预期: {{feature_merge.output.sample_count}}"
      executionPolicy:
        timeout: 5400

    # 步骤 6：质量报告
    - alias: "quality_report"
      type: "task"
      executionMode: "batch"
      trigger: "event:feature_merge.succeeded"
      taskRef:
        namespace: "com.company.feature"
        name: "quality_reporter"
        version: "1.0.0"
      inputs:
        dataset_path: "{{feature_merge.output_path}}"
      executionPolicy:
        timeout: 600
```

---

## 关键设计要点

### 1. 数据就绪检查

```yaml
dependsOn:
  - source: "log_extraction"
    waitFor: "data_ready"
    condition: "{{log_extraction.row_count > 0}}"
```

验证数据量，避免空数据进入下游

### 2. 并行优化

```yaml
# 用户特征和物品特征都依赖 data_cleaning
# 但彼此独立，可并行执行
user_features.dependsOn: [data_cleaning]
item_features.dependsOn: [data_cleaning]
```

节省 1 小时执行时间

### 3. 同步汇聚

```yaml
feature_merge.dependsOn:
  - user_features (completed)
  - item_features (completed)
```

必须等两路特征都完成

### 4. 质量门禁

```yaml
condition: "{{feature_merge.sample_count >= 100000000}}"
```

样本量不足时阻止生成报告

---

## 运行时行为

### 正常流程

```text
[00:00] 日志提取开始（30 分钟）
[00:30] 数据清洗开始（45 分钟）
[01:15] 用户特征 + 物品特征并行开始
  ├─ 用户特征（1.5 小时）
  └─ 物品特征（1 小时）
[02:45] 特征合并开始（等最慢的用户特征，1.5 小时）
[04:15] 质量报告（10 分钟）
[04:25] 完成

总耗时：4 小时 25 分钟
```

### 异常场景

```text
场景 1：数据提取为空
  ↓
清洗任务跳过（条件不满足）
  ↓
Pipeline 提前结束，标记失败

场景 2：用户特征失败
  ↓
物品特征继续执行（并行）
  ↓
特征合并等待超时
  ↓
Pipeline 失败

场景 3：样本量不足
  ↓
特征合并完成但样本数 < 1亿
  ↓
质量报告跳过（条件不满足）
  ↓
Pipeline 标记失败
```

---

## 监控指标

| 指标 | 阈值 | 说明 |
|------|------|------|
| 端到端时长 | < 6 小时 | 超时需优化 |
| 数据缩减率 | 500GB → 200GB | 特征压缩效果 |
| 样本量 | > 1 亿 | 训练数据充足性 |
| 特征覆盖率 | > 95% | 缺失值比例 |
| 正负样本比 | 1:4 ± 10% | 样本平衡性 |

---

## 总结

这是一个**典型的 Batch 数据处理场景**，验证了：

1. **data_ready 事件**：等待数据产出且非空
2. **并行执行**：独立任务并行优化
3. **同步汇聚**：多路依赖汇聚点
4. **条件执行**：基于数据量的质量门禁
5. **大数据处理**：TB 级数据的分布式计算
