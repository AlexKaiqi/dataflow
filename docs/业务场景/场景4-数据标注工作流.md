# 场景 4：数据标注工作流

## 场景概述

**业务需求**：自动标注 + 人工审核，构建训练数据

**执行模式**：Batch + 外部事件等待

**特殊性**：人在回路（Human-in-the-loop）

**执行时长**：数小时（含人工等待）

**核心特点**：条件路由、外部等待、递归重试、多分支汇聚

---

## 数据流程图

```text
待标注原始数据（10000 条）
  ↓
数据预处理
  ↓
自动标注（规则引擎）
  ↓
质量检测
  ├─ 高置信度（30%） → 自动通过
  ├─ 中置信度（50%） → 人工审核
  └─ 低置信度（20%） → 拒绝
  ↓
【等待人工审核完成】
  ↓
审核结果处理
  ├─ 通过（80%） → 写入训练集
  ├─ 拒绝（10%） → 写入拒绝集
  └─ 重新标注（10%） → 回到自动标注
  ↓
统计报告
```

---

## 详细步骤

### 1. 数据预处理

**输入**：原始图片/文本数据（10000 条）

**处理**：
- 图片格式标准化
- 文本清洗（去除特殊字符）
- 数据去重
- 生成唯一标识

**输出**：标准化数据

**执行时间**：5 分钟

### 2. 自动标注（规则引擎）

**输入**：标准化数据

**处理**：
- 基于规则的自动标注（关键词匹配、模板匹配）
- 计算置信度分数（0-1）
- 生成标注建议

**输出**：预标注结果 + 置信度

**执行时间**：10 分钟

### 3. 质量检测（置信度分流）

**输入**：预标注结果

**处理**：
```python
if confidence >= 0.9:
    status = "AUTO_APPROVED"    # 3000 条
elif confidence >= 0.7:
    status = "HUMAN_REVIEW"     # 5000 条
else:
    status = "REJECTED"         # 2000 条
```

**输出**：
- 自动通过：3000 条 → 直接写入训练集
- 人工审核：5000 条 → 发送审核任务
- 拒绝：2000 条 → 写入拒绝集

**执行时间**：2 分钟

### 4. 发送人工审核任务

**输入**：需要人工审核的数据（5000 条）

**处理**：
- 调用外部标注平台 API
- 分配给标注员
- 生成任务 ID

**输出**：任务 ID

**执行时间**：1 分钟

### 5. 等待人工完成（外部事件）

**处理**：
- Pipeline 进入等待状态
- 轮询标注平台（每分钟）
- 或监听 Webhook 回调

**等待时间**：2-4 小时（取决于标注员）

**超时设置**：24 小时

### 6. 获取审核结果

**输入**：任务 ID

**处理**：
- 拉取审核结果
- 解析审核动作（通过/拒绝/重新标注）

**输出**：人工审核结果（5000 条）

**执行时间**：2 分钟

### 7. 审核结果处理（条件路由）

**输入**：人工审核结果

**处理**：
```python
for result in results:
    if result["action"] == "APPROVE":
        write_to_training_set(result)    # 4000 条
    elif result["action"] == "REJECT":
        write_to_rejected_set(result)    # 500 条
    elif result["action"] == "RE_LABEL":
        send_to_relabel_queue(result)    # 500 条
```

**输出**：
- 通过：4000 条 → 训练集
- 拒绝：500 条 → 拒绝集
- 重新标注：500 条 → 重新标注队列

**执行时间**：3 分钟

### 8. 统计报告

**输入**：所有分支的处理结果

**处理**：
```json
{
  "total": 10000,
  "auto_approved": 3000,
  "human_approved": 4000,
  "rejected": 2500,
  "relabel_pending": 500,
  "training_set_size": 7000,
  "success_rate": 0.70
}
```

**输出**：统计报告

**执行时间**：1 分钟

---

## 特点分析

### ✅ 验证的设计要点

1. **条件路由**：根据置信度/审核结果分流到不同分支
2. **外部事件等待**：等待人工审核完成（长时间阻塞）
3. **可选依赖**：统计报告需等待所有可能的分支完成
4. **递归重试**：重新标注的数据可再次进入流程
5. **多分支汇聚**：多个写入任务最终汇聚到统计报告

### 核心依赖关系

| 步骤 | 依赖类型 | 等待条件 | 说明 |
|------|---------|---------|------|
| 自动标注 | **data_ready** | 预处理完成 | 串行依赖 |
| 质量检测 | **completed** | 标注完成 | 串行依赖 |
| 自动通过写入 | **条件满足** | 高置信度数据存在 | 条件执行 |
| 人工审核 | **条件满足** | 中置信度数据存在 | 条件执行 |
| 获取结果 | **external_event** | 人工审核完成 | 外部等待 |
| 结果处理 | **completed** | 审核结果返回 | 串行依赖 |
| 统计报告 | **可选汇聚** | 所有分支完成 | 多分支汇聚 |

---

## Pipeline 定义

```yaml
pipeline:
  name: "data_labeling_workflow"
  description: "数据标注工作流"
  
  inputVariables:
    - name: "input_data_path"
      type: "string"
    - name: "labeling_platform_endpoint"
      type: "string"
  
  nodes:
    # 步骤 1：预处理
    - alias: "preprocessing"
      type: "task"
      executionMode: "batch"
      trigger: "cron:@manual"
      taskRef:
        namespace: "com.company.labeling"
        name: "data_preprocessor"
        version: "1.0.0"
      inputs:
        input_path: "{{pipe.input_data_path}}"
    
    # 步骤 2：自动标注
    - alias: "auto_label"
      type: "task"
      executionMode: "batch"
      trigger: "event:preprocessing.succeeded"
      taskRef:
        namespace: "com.company.labeling"
        name: "rule_based_labeler"
        version: "1.0.0"
      inputs:
        data_path: "{{preprocessing.output_path}}"
    
    # 步骤 3：质量检测
    - alias: "quality_check"
      type: "task"
      executionMode: "batch"
      trigger: "event:auto_label.succeeded"
      taskRef:
        namespace: "com.company.labeling"
        name: "confidence_checker"
        version: "1.0.0"
      inputs:
        label_results: "{{auto_label.output_path}}"
        high_threshold: 0.9
        low_threshold: 0.7
    
    # 分支 A：自动通过
    - alias: "auto_approved_writer"
      type: "task"
      executionMode: "batch"
      trigger: "event:quality_check.succeeded"
      skipWhen: "quality_check.output.auto_approved_count == 0"
      taskRef:
        namespace: "com.company.labeling"
        name: "training_set_writer"
        version: "1.0.0"
      inputs:
        data_path: "{{quality_check.auto_approved_path}}"
    
    # 分支 B：人工审核
    - alias: "send_human_review"
      type: "task"
      executionMode: "batch"
      trigger: "event:quality_check.succeeded"
      skipWhen: "quality_check.output.human_review_count == 0"
      taskRef:
        namespace: "com.company.labeling"
        name: "review_task_sender"
        version: "1.0.0"
      inputs:
        data_path: "{{quality_check.human_review_path}}"
        platform_endpoint: "{{pipe.labeling_platform_endpoint}}"
    
    # 等待审核完成（外部事件）
    - alias: "fetch_review_results"
      type: "task"
      executionMode: "batch"
      trigger: "event:send_human_review.labeling_completed"
      taskRef:
        namespace: "com.company.labeling"
        name: "results_fetcher"
        version: "1.0.0"
      inputs:
        task_id: "{{send_human_review.task_id}}"
    
    # 审核通过分支
    - alias: "approved_writer"
      type: "task"
      executionMode: "batch"
      trigger: "event:fetch_review_results.succeeded"
      skipWhen: "fetch_review_results.output.approved_count == 0"
      taskRef:
        namespace: "com.company.labeling"
        name: "training_set_writer"
        version: "1.0.0"
      inputs:
        data_path: "{{fetch_review_results.approved_path}}"
    
    # 审核拒绝分支
    - alias: "rejected_writer"
      type: "task"
      executionMode: "batch"
      trigger: "event:fetch_review_results.succeeded"
      skipWhen: "fetch_review_results.output.rejected_count == 0"
      taskRef:
        namespace: "com.company.labeling"
        name: "rejected_set_writer"
        version: "1.0.0"
      inputs:
        data_path: "{{fetch_review_results.rejected_path}}"
    
    # 自动拒绝分支
    - alias: "auto_rejected_writer"
      type: "task"
      executionMode: "batch"
      trigger: "event:quality_check.succeeded"
      skipWhen: "quality_check.output.rejected_count == 0"
      taskRef:
        namespace: "com.company.labeling"
        name: "rejected_set_writer"
        version: "1.0.0"
      inputs:
        data_path: "{{quality_check.rejected_path}}"
    
    # 汇聚：统计报告
    - alias: "statistics"
      type: "task"
      executionMode: "batch"
      trigger: "event:auto_approved_writer.completed || event:approved_writer.completed || event:rejected_writer.completed || event:auto_rejected_writer.completed"
      taskRef:
        namespace: "com.company.labeling"
        name: "statistics_reporter"
        version: "1.0.0"
```

---

## 关键设计要点

### 1. 条件路由

```yaml
condition: "{{quality_check.auto_approved_count > 0}}"
condition: "{{quality_check.human_review_count > 0}}"
```

根据数据分布动态决定执行哪些分支

### 2. 外部事件等待

```yaml
waitFor: "external_event"
event_type: "labeling_task_completed"
timeout: 86400
```

等待外部系统（标注平台）完成，支持超时

### 3. 多源依赖

```yaml
dependsOn:
  - source: "quality_check"
  - source: "fetch_review_results"
    optional: true
```

拒绝集需要合并两个来源的数据

### 4. 可选依赖汇聚

```yaml
dependsOn:
  - source: "auto_approved_writer"
    optional: true
  - source: "approved_writer"
    optional: true
```

不是所有分支都会执行，统计报告等待实际执行的分支

---

## 监控指标

| 指标 | 阈值 | 说明 |
|------|------|------|
| 自动通过率 | > 30% | 规则引擎效果 |
| 人工审核通过率 | > 80% | 自动标注质量 |
| 人工审核时长 P99 | < 24 小时 | 标注效率 |
| 最终训练集大小 | > 70% | 数据利用率 |

---

## 总结

这是一个**典型的人在回路数据处理场景**，验证了：

1. **条件路由**：根据置信度动态分流
2. **external_event 等待**：等待人工审核完成
3. **多源依赖**：合并不同来源的数据
4. **可选依赖汇聚**：等待实际执行的分支
5. **长时间阻塞**：支持小时级等待
