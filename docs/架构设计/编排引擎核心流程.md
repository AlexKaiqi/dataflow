# 编排引擎核心流程

## 1. 概念定位

### 1.1 编排引擎的角色

**编排引擎是系统的核心主动方**：

```
编排引擎 (Orchestrator)
  ├─ 主动轮询（Polling）
  ├─ 主动查询事件管理器
  ├─ 主动查询变量池
  └─ 主动调度任务执行

事件管理器、变量池、任务执行器都是被动响应方
```

**设计原则**：拉模式（Pull）而非推模式（Push）

---

## 2. 流水线执行生命周期

### 2.1 执行阶段

```
流水线执行生命周期:

1. 初始化阶段
   └─ 创建执行实例、初始化变量池、发布启动事件

2. 运行阶段（循环）
   └─ 轮询检查 → 触发判断 → 节点执行 → 状态更新

3. 完成阶段
   └─ 发布完成事件、清理资源
```

### 2.2 状态转换

```
流水线状态机:

PENDING (待执行)
  ↓ start()
RUNNING (运行中)
  ↓ poll() - 循环
  ├─ 所有节点完成 → COMPLETED (已完成)
  ├─ 有节点失败 → FAILED (失败)
  └─ 手动取消 → CANCELLED (已取消)
```

---

## 3. 初始化流程

### 3.1 流程概述

```
启动流水线:
  1. 创建执行实例
  2. 初始化变量池
  3. 初始化事件管理器
  4. 发布 pipeline.started 事件
  5. 进入运行阶段
```

### 3.2 详细流程

```
输入:
  - pipeline_definition: 流水线定义
  - input_parameters: 输入参数

步骤1: 创建执行实例
  execution_id = generate_execution_id()
  execution = PipelineExecution(
    id: execution_id,
    pipeline_definition_id: pipeline_definition.id,
    status: PENDING,
    started_at: now()
  )

步骤2: 初始化变量池
  for each input_var in pipeline_definition.inputVariables:
    variable_pool.set(
      execution_id,
      f"pipeline.input.{input_var.name}",
      input_parameters[input_var.name]
    )
  
  # 写入系统变量
  variable_pool.set(execution_id, "system.execution_id", execution_id)
  variable_pool.set(execution_id, "system.started_at", now())

步骤3: 初始化节点状态
  for each node in pipeline_definition.nodes:
    execution.node_states[node.id] = NodeState(
      status: PENDING,
      started_at: null,
      completed_at: null
    )

步骤4: 发布启动事件
  event_manager.publish(
    execution_id,
    Event(type: "pipeline.started")
  )

步骤5: 更新状态并返回
  execution.status = RUNNING
  return execution
```

---

## 4. 轮询调度流程

### 4.1 轮询周期

**编排引擎的核心循环**：

```
while execution.status == RUNNING:
  1. 检查节点触发条件
  2. 执行可触发的节点
  3. 更新节点状态
  4. 检查流水线完成条件
  5. sleep(polling_interval)
```

### 4.2 详细流程

```
步骤1: 遍历所有节点
  pending_nodes = [node for node in nodes if state == PENDING]
  
  for node in pending_nodes:
    if should_trigger(execution_id, node):
      trigger_node(execution_id, node)

步骤2: 触发判断逻辑
  function should_trigger(execution_id, node):
    # 解析 startWhen 表达式
    expression = node.startWhen
    
    # 评估表达式
    result = evaluate_expression(execution_id, expression)
    
    return result == true

步骤3: 表达式评估
  function evaluate_expression(execution_id, expression):
    # 示例: "event:extract_data.completed && {{ extract_data.row_count > 0 }}"
    
    # 解析事件引用: event:extract_data.completed
    if contains_event_reference(expression):
      event_type = extract_event_type(expression)
      event_exists = event_manager.has_event(execution_id, event_type)
      if not event_exists:
        return false
    
    # 解析变量引用: {{ extract_data.row_count > 0 }}
    if contains_variable_reference(expression):
      resolved = variable_pool.resolve_expression(execution_id, expression)
      return resolved
    
    return true

步骤4: 检查完成条件
  function check_completion(execution):
    all_nodes_completed = all(node.status in [COMPLETED, SKIPPED])
    any_node_failed = any(node.status == FAILED)
    
    if any_node_failed:
      execution.status = FAILED
      event_manager.publish(execution_id, Event(type: "pipeline.failed"))
      return true
    
    if all_nodes_completed:
      execution.status = COMPLETED
      event_manager.publish(execution_id, Event(type: "pipeline.completed"))
      return true
    
    return false
```

---

## 5. 节点执行流程

### 5.1 流程概述

```
节点触发:
  1. 准备输入数据
  2. 调用任务执行器
  3. 处理执行结果
  4. 更新变量池
  5. 发布事件
```

### 5.2 详细流程

```
function trigger_node(execution_id, node):
  
  步骤1: 更新节点状态
    node_state.status = RUNNING
    node_state.started_at = now()
    
    event_manager.publish(
      execution_id,
      Event(type: f"{node.id}.started")
    )
  
  步骤2: 准备输入数据
    inputs = {}
    for key, expression in node.inputBindings:
      # 从变量池解析表达式
      value = variable_pool.resolve_expression(execution_id, expression)
      inputs[key] = value
  
  步骤3: 调用任务执行器
    try:
      if node.type == "task":
        result = task_executor.execute(
          task_definition: node.taskDefinition,
          inputs: inputs
        )
      elif node.type == "pipeline":
        result = execute_sub_pipeline(
          pipeline_definition: node.pipelineDefinition,
          inputs: inputs
        )
      
      步骤4: 处理成功结果
        # 写入输出变量
        for output_name, output_value in result.outputs:
          variable_pool.set(
            execution_id,
            f"{node.id}.{output_name}",
            output_value
          )
        
        # 更新节点状态
        node_state.status = COMPLETED
        node_state.completed_at = now()
        
        # 发布完成事件
        event_manager.publish(
          execution_id,
          Event(
            type: f"{node.id}.completed",
            payload: { outputs: result.outputs }
          )
        )
    
    catch Exception as e:
      步骤5: 处理失败
        node_state.status = FAILED
        node_state.error = str(e)
        node_state.failed_at = now()
        
        event_manager.publish(
          execution_id,
          Event(
            type: f"{node.id}.failed",
            payload: { error: str(e) }
          )
        )
```

---

## 6. 子流水线执行流程

### 6.1 流程概述

**子流水线是递归执行**：

```
父流水线节点类型为 pipeline:
  1. 创建子流水线的执行实例（独立 execution_id）
  2. 传递输入参数
  3. 递归调用编排引擎
  4. 等待子流水线完成
  5. 收集输出变量
```

### 6.2 详细流程

```
function execute_sub_pipeline(pipeline_definition, inputs):
  
  步骤1: 创建子执行实例
    child_execution_id = generate_execution_id()
    
    # 子流水线拥有独立的变量空间
    child_variable_pool = create_variable_pool(child_execution_id)
    child_event_manager = create_event_manager(child_execution_id)
  
  步骤2: 传递输入参数
    # 将父流水线的 inputs 写入子流水线的 pipeline.input.*
    for key, value in inputs:
      child_variable_pool.set(
        child_execution_id,
        f"pipeline.input.{key}",
        value
      )
  
  步骤3: 启动子流水线
    child_execution = orchestrator.start(
      pipeline_definition: pipeline_definition,
      execution_id: child_execution_id,
      variable_pool: child_variable_pool,
      event_manager: child_event_manager
    )
  
  步骤4: 等待子流水线完成
    while child_execution.status == RUNNING:
      orchestrator.poll(child_execution)
      sleep(polling_interval)
  
  步骤5: 收集输出变量
    outputs = {}
    for output_var in pipeline_definition.outputVariables:
      # 从子流水线变量池读取输出
      value = child_variable_pool.get(
        child_execution_id,
        f"pipeline.output.{output_var.name}"
      )
      outputs[output_var.name] = value
  
  步骤6: 返回结果
    return ExecutionResult(
      status: child_execution.status,
      outputs: outputs
    )
```

---

## 7. 表达式评估流程

### 7.1 表达式类型

**事件表达式**：

```
格式: event:{event_type}

示例:
  event:extract_data.completed
  event:pipeline.started

评估方式:
  event_manager.has_event(execution_id, event_type)
```

**变量表达式**：

```
格式: {{ variable_reference }}

示例:
  {{ extract_data.row_count > 0 }}
  {{ pipeline.input.start_date }}

评估方式:
  variable_pool.resolve_expression(execution_id, expression)
```

**组合表达式**：

```
格式: event:{event_type} && {{ condition }}

示例:
  event:extract_data.completed && {{ extract_data.row_count > 0 }}

评估方式:
  1. 评估事件部分 → event_manager.has_event(...)
  2. 评估变量部分 → variable_pool.resolve_expression(...)
  3. 逻辑运算: result = event_result && variable_result
```

### 7.2 评估流程

```
function evaluate_expression(execution_id, expression):
  
  步骤1: 解析表达式
    tokens = parse_expression(expression)
    # 示例: ["event:node_a.completed", "&&", "{{ node_a.count > 0 }}"]
  
  步骤2: 评估每个 token
    results = []
    for token in tokens:
      if is_event_reference(token):
        event_type = extract_event_type(token)
        result = event_manager.has_event(execution_id, event_type)
        results.append(result)
      
      elif is_variable_expression(token):
        result = variable_pool.resolve_expression(execution_id, token)
        results.append(result)
      
      elif is_operator(token):
        results.append(token)
  
  步骤3: 执行逻辑运算
    # 示例: [true, "&&", true] → true
    final_result = evaluate_logical(results)
    
    return final_result
```

---

## 8. 错误处理流程

### 8.1 节点失败处理

```
节点执行失败:
  1. 捕获异常
  2. 更新节点状态为 FAILED
  3. 发布 {node_id}.failed 事件
  4. 检查是否有 retryWhen 配置
  5. 如果可以重试 → 标记为 PENDING（等待重试触发）
  6. 如果不能重试 → 标记为 FAILED（最终失败）
```

### 8.2 重试流程

```
配置重试:
  node:
    retryWhen: "event:task.failed && {{ attempts < 3 }}"

重试触发:
  1. 节点失败后发布 {node_id}.failed 事件
  2. 轮询时评估 retryWhen 表达式
  3. 如果条件满足 → 重新触发节点执行
  4. 增加重试计数器
```

### 8.3 流水线失败处理

```
流水线失败条件:
  - 任何节点最终失败（FAILED）
  - 手动取消

处理流程:
  1. 更新流水线状态为 FAILED 或 CANCELLED
  2. 发布 pipeline.failed 或 pipeline.cancelled 事件
  3. 停止所有运行中的节点
  4. 清理资源
```

---

## 9. 时序图

### 9.1 完整执行流程

```
用户             编排引擎         事件管理器        变量池         任务执行器

启动流水线
  |
  |--创建执行--->|
  |              |
  |              |--初始化---->|
  |              |                |
  |              |--初始化---->|          |
  |              |                         |
  |              |--发布事件->|            |
  |              |             (pipeline.started)
  |              |                         |
  |<---返回-----|                         |
  |              |                         |
轮询开始         |                         |
  |              |---查询事件->|            |
  |              |             (startWhen?)
  |              |<--返回------|            |
  |              |                         |
  |              |---解析变量-->|          |
  |              |              (inputBindings)
  |              |<--返回-------|          |
  |              |                         |
  |              |---执行任务------------->|
  |              |                         |
  |              |<--返回结果--------------|
  |              |                         |
  |              |---写入变量-->|          |
  |              |              (outputs)  |
  |              |<--确认-------|          |
  |              |                         |
  |              |---发布事件->|            |
  |              |             (node.completed)
  |              |                         |
循环轮询...      |                         |
  |              |                         |
所有节点完成     |                         |
  |              |---发布事件->|            |
  |              |             (pipeline.completed)
  |<---通知-----|                         |
```

---

## 10. 设计要点

### 10.1 主动轮询

**为什么用轮询而不是事件驱动？**

```
优点:
  ✅ 实现简单，逻辑集中在编排引擎
  ✅ 状态一致性好，易于理解和调试
  ✅ 不需要复杂的事件订阅机制
  ✅ 易于实现分布式（多个引擎实例轮询）

缺点:
  ❌ 有轮询延迟（可通过调整轮询间隔缓解）
  ❌ 空闲时也会轮询（可通过智能轮询优化）
```

### 10.2 独立执行空间

**每个执行实例独立**：

```
隔离保证:
  - 独立的 execution_id
  - 独立的变量池
  - 独立的事件管理器
  - 独立的节点状态

优势:
  - 支持并发执行
  - 支持嵌套流水线
  - 易于测试和调试
```

### 10.3 表达式驱动

**控制流由表达式定义**：

```
灵活性:
  - 支持事件触发
  - 支持条件分支
  - 支持多路汇聚
  - 支持定时触发

扩展性:
  - 可以添加新的表达式类型
  - 可以支持复杂的逻辑组合
  - 不需要修改编排引擎
```

---

## 11. 总结

### 11.1 核心流程

| 阶段 | 主要操作 |
|------|---------|
| **初始化** | 创建执行实例、初始化变量池和事件管理器 |
| **轮询调度** | 检查触发条件、执行节点、更新状态 |
| **节点执行** | 准备输入、调用执行器、处理输出、发布事件 |
| **完成清理** | 发布完成事件、清理资源 |

### 11.2 关键特性

- **拉模式架构**：编排引擎主动轮询查询
- **表达式驱动**：通过表达式评估决定执行流程
- **独立执行空间**：每个执行实例完全隔离
- **递归子流水线**：子流水线作为节点递归执行

### 11.3 设计优势

```
简单性:
  - 逻辑集中在编排引擎
  - 其他组件只是数据服务
  - 易于理解和维护

可靠性:
  - 状态一致性好
  - 易于恢复和重试
  - 支持分布式部署

灵活性:
  - 表达式可以表达复杂逻辑
  - 支持多种触发模式
  - 易于扩展新功能
```
