# 训练前数据处理场景汇总

本目录包含 5 个聚焦**训练前数据处理**的真实场景，用于验证数据流引擎的领域模型设计。

---

## 场景概览

| 场景 | 执行模式 | 核心特点 | 验证要点 |
|------|---------|---------|---------|
| [场景1：批量特征工程](./场景1-批量特征工程.md) | **Batch** | 大数据量、并行优化、串行汇聚 | data_ready、并行、同步汇聚 |
| [场景2：增量数据处理](./场景2-增量数据处理.md) | **Scheduled Batch** | 定时调度、时间分区、补跑 | cron、execution_date、catchup |
| [场景3：流式数据清洗](./场景3-流式数据清洗.md) | **Streaming** | 持续运行、窗口聚合、状态管理 | streaming、checkpoint、服务依赖 |
| [场景4：数据标注工作流](./场景4-数据标注工作流.md) | **Batch + 外部事件** | 人在回路、条件路由、多分支汇聚 | external_event、条件执行、可选依赖 |
| [场景5：用户行为分析与推荐](./场景5-用户行为分析与推荐.md) | **流批一体** | 实时流+批处理、复杂依赖、审批、模型全流程 | streaming+batch、条件分支、多路汇聚、approval |

---

## 按执行模式分类

### Batch（批处理）
**场景 1：批量特征工程**
- 一次性大批量数据处理
- TB 级数据的分布式计算
- 并行优化 + 同步汇聚

### Scheduled Batch（定时批处理）
**场景 2：增量数据处理**
- 定时触发（cron）
- 时间分区数据（execution_date）
- 支持历史补跑（catchup）

### Streaming（流式处理）
**场景 3：流式数据清洗**
- 7x24 持续运行
- 窗口聚合和状态管理
- 秒级延迟

### Batch + 外部事件
**场景 4：数据标注工作流**
- 条件路由
- 外部人工审核等待
- 多分支汇聚

### 流批一体（Lambda 架构）
**场景 5：用户行为分析与推荐**
- 实时流处理 + 批量特征工程
- 复杂依赖关系（并行、汇聚、条件分支）
- 人工审批 + 模型全流程
- 外部事件触发（定时、配置变更、模型更新）

---

## 按数据特征分类

### 大数据量（TB 级）
- **场景 1**：500GB → 200GB 特征数据
- **场景 5**：7天历史数据 + 实时流 + 模型训练

### 增量数据（日级）
- **场景 2**：每日 30GB 增量处理

### 流式数据（实时）
- **场景 3**：10000 条/秒持续流
- **场景 5**：Kafka 用户点击流 + 模型推理流

### 小批量数据（万级）
- **场景 4**：10000 条标注任务

---

## 验证的核心设计

### 1. 执行模式（executionMode）

| 模式 | 场景 | 特点 |
|------|------|------|
| **batch** | 场景 1, 4 | 一次性执行，有明确完成状态 |
| **scheduled** | 场景 2 | 定时触发，支持 cron 和 catchup |
| **streaming** | 场景 3 | 持续运行，无完成状态 |

### 2. 依赖等待条件（waitFor）

| 条件 | 场景 | 说明 |
|------|------|------|
| **data_ready** | 场景 1, 2, 4 | 等待数据产出且非空 |
| **completed** | 场景 1, 2, 4 | 等待任务成功完成 |
| **healthy** | 场景 3 | 等待服务可用 |
| **running** | 场景 3 | 等待服务运行中 |
| **external_event** | 场景 4 | 等待外部事件 |

### 3. 高级特性

| 特性 | 场景 | 说明 |
|------|------|------|
| **并行执行** | 场景 1 | 用户特征和物品特征并行 |
| **同步汇聚** | 场景 1 | 特征合并等待两路完成 |
| **条件执行** | 场景 1, 4 | 基于条件决定是否执行 |
| **时间分区** | 场景 2 | execution_date 处理特定日期 |
| **补跑** | 场景 2 | catchup 自动补跑历史 |
| **窗口聚合** | 场景 3 | 5 分钟滚动窗口 |
| **状态管理** | 场景 3 | 去重窗口状态 |
| **Checkpoint** | 场景 3 | 支持故障恢复 |
| **外部等待** | 场景 4 | 等待人工审核（小时级） |
| **多源依赖** | 场景 4 | 合并不同来源数据 |
| **可选依赖** | 场景 4 | 不是所有分支都执行 |
| **流批一体** | 场景 5 | 实时流 + 批处理混合编排 |
| **条件分支** | 场景 5 | 基于质量得分的条件路由 |
| **多路汇聚(AND)** | 场景 5 | 等待多个并行任务全部完成 |
| **多路汇聚(OR)** | 场景 5 | 任一分支完成即可继续 |
| **人工审批** | 场景 5 | 特征质量审批 + 模型部署审批 |
| **生命周期管理** | 场景 5 | streaming 任务启停重启控制 |

---

## 场景对比

### 场景 1 vs 场景 2：批量 vs 增量

| 维度 | 场景 1（批量特征） | 场景 2（增量处理） |
|------|-------------------|-------------------|
| 触发 | 手动/临时 | **定时（cron）** |
| 数据范围 | 全量（7 天） | **增量（1 天）** |
| 时间概念 | 无 | **execution_date** |
| 数据量 | 500GB | 30GB |
| 频率 | 每周 | **每天** |
| 补跑 | 手动重跑 | **catchup 自动** |

### 场景 2 vs 场景 3：批量 vs 流式

| 维度 | 场景 2（增量批量） | 场景 3（流式清洗） |
|------|-------------------|-------------------|
| 执行模式 | Scheduled Batch | **Streaming** |
| 触发 | 定时（cron） | **消息驱动** |
| 完成状态 | 有 | **无** |
| 延迟 | 小时级 | **秒级** |
| 状态 | 无状态 | **有状态（窗口）** |
| 容错 | 重跑 | **Checkpoint** |

### 场景 1 vs 场景 4：简单依赖 vs 复杂依赖

| 维度 | 场景 1（特征工程） | 场景 4（标注工作流） |
|------|-------------------|---------------------|
| 依赖类型 | 数据就绪、任务完成 | **外部事件、条件** |
| 分支结构 | 并行 → 汇聚 | **条件分流 → 汇聚** |
| 等待时长 | 分钟级 | **小时级** |
| 可选依赖 | 无 | **有** |
| 递归 | 无 | **有（重新标注）** |

---

## 覆盖的数据处理类型

### ETL（Extract, Transform, Load）
- **场景 1**：特征工程（Transform）
- **场景 2**：增量 ETL（全流程）
- **场景 3**：流式 ETL（实时）

### 数据清洗
- **场景 1**：批量清洗和去重
- **场景 2**：增量去重和验证
- **场景 3**：流式清洗和过滤

### 特征工程
- **场景 1**：用户和物品特征生成

### 数据标注
- **场景 4**：自动标注 + 人工审核

---

## 场景 5：流批一体典型场景

**场景 5** 是最复杂和典型的场景，综合展示了：

### 架构特点
- **Lambda 架构**：实时流（3个节点持续运行）+ 批量处理（每日定时触发）
- **复杂依赖**：并行（3个特征工程）、AND汇聚、OR汇聚、条件分支
- **全流程覆盖**：数据摄入 → 特征工程 → 模型训练 → 人工审批 → 在线推理

### 依赖关系图
```
实时流链路（持续运行）:
  Kafka摄入 → 实时清洗 → 实时聚合 → Redis

批处理链路（每日2点触发）:
  提取历史数据 → 批量清洗 → [并行3路特征工程] 
    → [AND汇聚] 特征合并验证 
      → [条件分支] 
         ├─ 质量≥0.9 → 自动入库 ──┐
         └─ 质量<0.9 → 审批 → 审批后入库 ─┘
           → [OR汇聚] 模型训练 
             → 模型部署审批 
               → 推理服务（持续运行）
                 → 结果落库（持续批量写入）
```

### 验证的核心设计
1. **流批混合编排**：streaming + batch 任务在同一 Pipeline
2. **多种汇聚模式**：AND（等待全部完成）、OR（任一完成）
3. **条件分支**：基于 `quality_score` 动态路由
4. **人工审批**：Approval 任务类型（特征质量 + 模型部署）
5. **生命周期管理**：`startWhen/stopWhen/restartWhen` 控制 streaming 任务
6. **外部事件触发**：定时、配置变更、模型更新、外部请求

---

## 总结

这 5 个场景聚焦**训练前数据处理 + 模型全流程**，覆盖了：

### 数据处理模式
- ✅ 批量处理（大数据离线计算）
- ✅ 增量处理（定时增量更新）
- ✅ 流式处理（实时数据清洗）
- ✅ 人在回路（标注工作流）
- ✅ 流批一体（Lambda 架构）

### 核心技术要点
- ✅ 分布式计算（Spark/Flink）
- ✅ 并行优化（独立任务并行）
- ✅ 时间分区（按日期处理）
- ✅ 状态管理（窗口去重）
- ✅ 容错恢复（Checkpoint）
- ✅ 条件路由（动态分流）
- ✅ 多路汇聚（AND/OR）
- ✅ 人工审批（Approval）
- ✅ 生命周期管理（streaming 控制）
- ✅ 外部集成（人工审核）

### 验证的领域模型设计
- ✅ **3 种执行模式**：batch、scheduled、streaming
- ✅ **5 种依赖条件**：data_ready、completed、healthy、running、external_event
- ✅ **10+ 高级特性**：并行、汇聚、条件、窗口、checkpoint、补跑等

通过这些场景，充分验证了数据流引擎在**训练前数据处理**领域的**完整性**和**合理性**。
